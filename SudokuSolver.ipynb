{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef2bb6-0dcd-4d3d-a43f-c33309057d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0a881-50b9-46a8-836e-36bb02ec7b26",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0076e-a041-470b-8800-4c1c1e0d2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be05fca0-50b2-460e-b926-afa579bfc4d3",
   "metadata": {},
   "source": [
    "# Define Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2182dc4-cf67-4712-bf23-2db2801a5471",
   "metadata": {},
   "source": [
    "## acquire_image(): Capture a screenshot of the Sudoku puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a875f1-c2a3-4f54-9e63-8df2e81957d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_image():\n",
    "    \"\"\"\n",
    "    Capture the current screen and return it as an image.\n",
    "\n",
    "    Returns:\n",
    "        screenshot (PIL.Image.Image): The captured screenshot.\n",
    "    \"\"\"\n",
    "    # Using pyautogui's screenshot feature to capture the screen\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    return screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb7170-4734-4846-8d45-f81d11c5b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(image, title=\"Image\"):\n",
    "    \"\"\"\n",
    "    Visualize an image using matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        image (PIL.Image.Image or numpy.ndarray): The image to visualize.\n",
    "        title (str): The title of the visualization.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b910f-2f83-4868-994c-ca45a75988c5",
   "metadata": {},
   "source": [
    "## preprocess_image(image): Apply preprocessing steps to prepare the image for grid detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc02dd4-bc3c-434e-9e58-b37ba6b28105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Apply preprocessing steps to invert the image colors and make it similar to MNIST format.\n",
    "    \n",
    "    Parameters:\n",
    "        image (PIL.Image.Image): The input image to preprocess.\n",
    "    \n",
    "    Returns:\n",
    "        preprocessed_image (numpy.ndarray): The preprocessed image ready for further analysis.\n",
    "    \"\"\"\n",
    "    # Convert the PIL Image to an OpenCV image (PIL uses RGB, OpenCV uses BGR)\n",
    "    open_cv_image = np.array(image)\n",
    "    # Convert RGB to BGR \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to smooth out the image\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding to create a binary image\n",
    "    # This step inverts the image: background becomes black, digits become white\n",
    "    threshold_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                            cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # No need for edge detection, as we want to keep the digits filled\n",
    "    \n",
    "    return threshold_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb55b4ec-6826-4576-bbc7-294046be98fe",
   "metadata": {},
   "source": [
    "## detect_sudoku_grid(preprocessed_image): Detect the grid and segment it into individual cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4788728-03bc-4799-98ca-6cab3074a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sudoku_grid(preprocessed_image):\n",
    "    \"\"\"\n",
    "    Detect the Sudoku grid and divide it into 9x9 cells.\n",
    "    \n",
    "    Parameters:\n",
    "        preprocessed_image (numpy.ndarray): The preprocessed image of the Sudoku puzzle.\n",
    "        \n",
    "    Returns:\n",
    "        cells (list of numpy.ndarray): List of 9x9 cell images of the Sudoku grid.\n",
    "    \"\"\"\n",
    "    # Step 1: Find contours\n",
    "    contours, _ = cv2.findContours(preprocessed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Assume the largest contour is the Sudoku grid\n",
    "    max_area = 0\n",
    "    sudoku_contour = None\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            sudoku_contour = contour\n",
    "    \n",
    "    if sudoku_contour is None:\n",
    "        print(\"Sudoku grid not found\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Apply perspective transform to get a top-down view of the Sudoku grid\n",
    "    # Find the corners of the grid\n",
    "    peri = cv2.arcLength(sudoku_contour, True)\n",
    "    approx = cv2.approxPolyDP(sudoku_contour, 0.02 * peri, True)\n",
    "    \n",
    "    if len(approx) != 4:\n",
    "        print(\"Could not find corners of the grid\")\n",
    "        return None\n",
    "    \n",
    "    # Order the corners\n",
    "    ordered_corners = order_points(np.squeeze(approx))\n",
    "    \n",
    "    # The maximum width and height of the grid\n",
    "    side = max([\n",
    "        np.linalg.norm(ordered_corners[0] - ordered_corners[1]),\n",
    "        np.linalg.norm(ordered_corners[1] - ordered_corners[2]),\n",
    "        np.linalg.norm(ordered_corners[2] - ordered_corners[3]),\n",
    "        np.linalg.norm(ordered_corners[3] - ordered_corners[0])\n",
    "    ])\n",
    "    \n",
    "    # Destination points for the perspective transform\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [side - 1, 0],\n",
    "        [side - 1, side - 1],\n",
    "        [0, side - 1]], dtype=\"float32\")\n",
    "    \n",
    "    # Apply perspective transform\n",
    "    M = cv2.getPerspectiveTransform(ordered_corners, dst)\n",
    "    warped = cv2.warpPerspective(preprocessed_image, M, (int(side), int(side)))\n",
    "    \n",
    "    # Step 3: Divide the warped image into 9x9 cells\n",
    "    cells = []\n",
    "    cell_size = side / 9\n",
    "    for i in range(9):\n",
    "        row = []\n",
    "        for j in range(9):\n",
    "            start_x = int(j * cell_size)\n",
    "            start_y = int(i * cell_size)\n",
    "            cell = warped[start_y:start_y + int(cell_size), start_x:start_x + int(cell_size)]\n",
    "            row.append(cell)\n",
    "        cells.append(row)\n",
    "    \n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dae311-c980-4c25-93ff-5df20540541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    \"\"\"\n",
    "    Order the points in clockwise order starting from the top-left point.\n",
    "    \"\"\"\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3efaee1-ff56-4569-87c6-502baa43d5dd",
   "metadata": {},
   "source": [
    "## Cropping cells before preprocessing for mnist to get rid of borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c0017-34ff-4186-82e7-98005c34f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_central_area(cell, border_size=4):\n",
    "    \"\"\"\n",
    "    Crops the cell image to remove a border of `border_size` pixels from all sides.\n",
    "    \n",
    "    Parameters:\n",
    "    - cell: A 28x28 numpy array representing the cell image.\n",
    "    - border_size: The width of the border to remove from each side.\n",
    "    \n",
    "    Returns:\n",
    "    - A cropped cell image.\n",
    "    \"\"\"\n",
    "    cropped_cell = cell[border_size:-border_size, border_size:-border_size]\n",
    "    return cropped_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe4c8b-2005-4f84-8269-a65b8d86ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_cells_grid(cells, border_size=6):\n",
    "    \"\"\"\n",
    "    Crop the borders from each cell in a 9x9 grid.\n",
    "    \n",
    "    Parameters:\n",
    "    - cells: A 9x9 grid of cell images.\n",
    "    - border_size: The width of the border to remove from each side.\n",
    "    \n",
    "    Returns:\n",
    "    - A 9x9 grid of cropped cell images.\n",
    "    \"\"\"\n",
    "    cropped_cells = []\n",
    "    for row in cells:\n",
    "        cropped_row = [crop_to_central_area(cell, border_size) for cell in row]\n",
    "        cropped_cells.append(cropped_row)\n",
    "    return cropped_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e95777-f866-41df-82f0-98e0a7e396ad",
   "metadata": {},
   "source": [
    "## Visualizing cells grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7b5db-7a06-46c7-9c2f-0aa7e4f94a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cells_grid(cells, title=\"Cells Grid\"):\n",
    "    \"\"\"\n",
    "    Visualize a grid of cells.\n",
    "\n",
    "    Parameters:\n",
    "        cells (list of list of numpy.ndarray): A 9x9 grid of cell images.\n",
    "        title (str): Title for the plot.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(9, 9, figsize=(9, 9))\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    for i, row in enumerate(cells):\n",
    "        for j, cell in enumerate(row):\n",
    "            ax = axs[i, j]\n",
    "            ax.imshow(cell, cmap='gray')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f6857-aaef-4bf5-9022-2e6be7e27875",
   "metadata": {},
   "source": [
    "## Detecting Empty Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3a6dd-5c3a-4660-951f-917f2fe8a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of non-empty cell coordinates\n",
    "non_empty_cells_coordinates = [(0,0),(0,1),(0,2),(0,3),(0,4),(0,5),(0,7),(1,2),(1,6),(2,0),\n",
    "                               (2,6),(2,7),(2,8),(3,3),(3,4),(3,5),(3,7),(4,3),(4,6),(5,1),\n",
    "                               (5,3),(5,4),(5,5),(6,0),(6,1),(6,2),(6,8),(7,2),(7,6),(8,1),\n",
    "                               (8,3),(8,4),(8,5),(8,6),(8,7),(8,8)]\n",
    "\n",
    "# Convert to a set for faster lookup\n",
    "non_empty_cells_set = set(non_empty_cells_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d48df2-fad8-4162-a9f3-91b2f30f31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cell_empty(cropped_cell, threshold=1):\n",
    "    \"\"\"\n",
    "    Determine if a cell is empty based on the average pixel intensity.\n",
    "\n",
    "    Parameters:\n",
    "    - cell: Cropped cell image as a numpy array.\n",
    "    - threshold: Pixel intensity threshold to consider the cell as empty.\n",
    "\n",
    "    Returns:\n",
    "    - True if the cell is considered empty, False otherwise.\n",
    "    \"\"\"\n",
    "    return np.mean(cropped_cell) < threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def143cd-2e4e-43ef-a535-3ba3dc0378ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cell_grid_status(cropped_cells, threshold=1):\n",
    "    \"\"\"\n",
    "    Print a 9x9 grid indicating whether each cell is empty or contains something and\n",
    "    returns a list of indices for empty cells.\n",
    "\n",
    "    Parameters:\n",
    "    - cropped_cells: A 9x9 grid (list of lists) of cropped cell images.\n",
    "    - threshold: Pixel intensity threshold to consider a cell as empty.\n",
    "\n",
    "    Each cell is represented by:\n",
    "    - '#': The cell is detected as having something in it.\n",
    "    - '-': The cell is detected to be empty.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples, where each tuple represents the indices of an empty cell (row_index, column_index).\n",
    "    \"\"\"\n",
    "    empty_cells_indices = []  # Initialize an empty list to store indices of empty cells\n",
    "    print(\"\\nDetecting Empty Cells\\n# cell contains numbers\\n- cell is empty\\n\")\n",
    "    for i, row in enumerate(cropped_cells):\n",
    "        for j, cell in enumerate(row):\n",
    "            if is_cell_empty(cell, threshold):\n",
    "                print('-', end=' ')\n",
    "                empty_cells_indices.append((i, j))  # Add index of empty cell to the list\n",
    "            else:\n",
    "                print('#', end=' ')\n",
    "        print()  # Move to the next line after printing each row\n",
    "    \n",
    "    return empty_cells_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3a81d-5358-4562-a35a-fb04ea6e2367",
   "metadata": {},
   "source": [
    "## preprocess_for_mnist(cell): Preprocess a cell image for MNIST model compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07d303-65e8-4543-870b-8add0c0f4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_mnist(cell):\n",
    "    # Assuming cell has been optionally cropped already\n",
    "    resized = cv2.resize(cell, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY) if len(resized.shape) == 3 else resized\n",
    "    scaled = gray / 255.0\n",
    "    return np.expand_dims(scaled, axis=0)  # Correct shape should be (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896a229-b1cf-44cb-ac3e-eecc090c1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cells_grid_for_mnist(preprocessed_cells):\n",
    "    \"\"\"\n",
    "    Visualize a 9x9 grid of Sudoku cell images after preprocessing them for MNIST.\n",
    "    \n",
    "    Parameters:\n",
    "        preprocessed_cells (list of list of numpy.ndarray): The 9x9 grid of preprocessed cell images.\n",
    "    \"\"\"\n",
    "    # Initialize a 9x9 grid of subplots\n",
    "    fig, axs = plt.subplots(9, 9, figsize=(9, 9))\n",
    "    fig.suptitle(\"Cells Preprocessed for MNIST\", fontsize=16)\n",
    "    \n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            # Get the preprocessed cell, assuming preprocessing includes necessary resizing and normalization\n",
    "            preprocessed_cell = preprocessed_cells[i][j].squeeze()\n",
    "            # Ensure we still have a 2D array after squeezing. If not, it's likely a grayscale image.\n",
    "            if preprocessed_cell.ndim == 2:\n",
    "                axs[i, j].imshow(preprocessed_cell, cmap='gray')\n",
    "            else:\n",
    "                axs[i, j].imshow(preprocessed_cell)\n",
    "            axs[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b36226-c70f-45d7-b969-5a9e1f1d510b",
   "metadata": {},
   "source": [
    "## recognize digit(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ddc46b-21eb-4196-a7b0-95c5347bc64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_digit(cell, model):\n",
    "    preprocessed = preprocess_for_mnist(cell)\n",
    "    prediction = model.predict(preprocessed)\n",
    "    return np.argmax(prediction)  # Return the digit with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff554d-4354-47b1-a658-8df21697a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_digits(cropped_cells, model, empty_cells_indices):\n",
    "    \"\"\"\n",
    "    Recognize digits within each cell, populating the Sudoku matrix, using a list of empty cell indices.\n",
    "\n",
    "    Parameters:\n",
    "    - cropped_cells: A 9x9 grid (list of lists) of cropped cell images.\n",
    "    - model: The trained MNIST model for digit recognition.\n",
    "    - empty_cells_indices: A list of tuples indicating the indices of empty cells.\n",
    "\n",
    "    Returns:\n",
    "    - A 9x9 Sudoku matrix populated with recognized digits or 0 for empty cells.\n",
    "    \"\"\"\n",
    "    # Initialize the sudoku matrix with placeholders to indicate non-reviewed cells\n",
    "    sudoku_matrix = [[-1 for _ in range(9)] for _ in range(9)]\n",
    "\n",
    "    for i, row in enumerate(cropped_cells):\n",
    "        for j, cell in enumerate(row):\n",
    "            if (i, j) in empty_cells_indices:\n",
    "                sudoku_matrix[i][j] = -1  # Mark cell as empty\n",
    "            else:\n",
    "                digit = recognize_digit(cell, model)\n",
    "                sudoku_matrix[i][j] = digit  # Update with recognized digit\n",
    "    return sudoku_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324dce1-5af2-4fae-8a74-a035ffeb325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sudoku_matrix(sudoku_matrix):\r\n",
    "    print(\"Sudoku Grid:\")\r\n",
    "    for i, row in enumerate(sudoku_matrix):\r\n",
    "        if i % 3 == 0 and i != 0:  # Add a horizontal separator line between each 3 rows\r\n",
    "            print(\"- - - - - - - - - - -\")\r\n",
    "        \r\n",
    "        for j, num in enumerate(row):\r\n",
    "            if j % 3 == 0 and j != 0:  # Add a vertical separator between each 3 columns\r\n",
    "                print(\"| \", end=\"\")\r\n",
    "            \r\n",
    "            if j == 8:  # If it's the last number in the row, move to the next line after printing\r\n",
    "                print(num)\r\n",
    "            else:  # Else, stay on the same line\r\n",
    "                print(str(num) +\" \", end=\"\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e970335-aa84-4261-882a-7ab94f590f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solve Sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23302ca-ccbf-4545-a8f5-4d144b45b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc07f2-b129-486e-a738-9742d889ab42",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2f22f-2dd3-424e-94d8-f970db7e0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Step 1: Capture the Sudoku puzzle screenshot\n",
    "    screenshot = acquire_image()\n",
    "    visualize_image(screenshot, \"Original Screenshot\")\n",
    "\n",
    "    # Step 2: Preprocess the image to facilitate grid detection + visualizatoin\n",
    "    preprocessed_image = preprocess_image(screenshot)\n",
    "    visualize_image(preprocessed_image, \"Preprocessed Image\")\n",
    "\n",
    "    # Step 3: Detect the Sudoku grid and extract individual cells + visualization\n",
    "    cells = detect_sudoku_grid(preprocessed_image)\n",
    "    if not cells:\n",
    "        print(\"Failed to detect Sudoku grid or extract cells.\")\n",
    "        return\n",
    "    visualize_cells_grid(cells, \"Extracted Cells\")\n",
    "    \n",
    "    # Step 4: Crop the cells to remove borders + visualization\n",
    "    cropped_cells = crop_cells_grid(cells, border_size=6)\n",
    "    visualize_cells_grid(cropped_cells, \"Cropped Cells\")\n",
    "\n",
    "    # Step 5: Check thresholding for empty cells and capture empty cell indices\n",
    "    empty_cells_indices = print_cell_grid_status(cropped_cells, threshold=1)\n",
    "\n",
    "    # Step 6: Preprocess the cropped cells for MNIST (visualization step included)\n",
    "    visualize_cells_grid_for_mnist(cropped_cells)\n",
    "\n",
    "    # Path to the pre-trained digit recognition model\n",
    "    model_path = 'my_emnist_model.keras'\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Step 7: Recognize digits within each cell to populate the Sudoku matrix\n",
    "    # Now passing the empty_cells_indices to recognize_digits\n",
    "    sudoku_matrix = recognize_digits(cropped_cells, model, empty_cells_indices)\n",
    "\n",
    "    print_sudoku_matrix(sudoku_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a099d8c-7fed-4c0d-a7fa-1d1de9ceb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the main program\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c99c549-5bc1-45e0-bec4-e1971dc8d3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cd6c7-f46b-4202-b052-6be8c3417e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
