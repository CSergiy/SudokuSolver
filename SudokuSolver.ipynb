{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfef2bb6-0dcd-4d3d-a43f-c33309057d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0a881-50b9-46a8-836e-36bb02ec7b26",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e0076e-a041-470b-8800-4c1c1e0d2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be05fca0-50b2-460e-b926-afa579bfc4d3",
   "metadata": {},
   "source": [
    "# Define Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2182dc4-cf67-4712-bf23-2db2801a5471",
   "metadata": {},
   "source": [
    "## acquire_image(): Capture a screenshot of the Sudoku puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a875f1-c2a3-4f54-9e63-8df2e81957d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_image():\n",
    "    \"\"\"\n",
    "    Capture the current screen and return it as an image.\n",
    "\n",
    "    Returns:\n",
    "        screenshot (PIL.Image.Image): The captured screenshot.\n",
    "    \"\"\"\n",
    "    # Using pyautogui's screenshot feature to capture the screen\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    return screenshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b910f-2f83-4868-994c-ca45a75988c5",
   "metadata": {},
   "source": [
    "## preprocess_image(image): Apply preprocessing steps to prepare the image for grid detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc02dd4-bc3c-434e-9e58-b37ba6b28105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Apply preprocessing steps to make the Sudoku grid easier to analyze.\n",
    "    \n",
    "    Parameters:\n",
    "        image (PIL.Image.Image): The input image to preprocess.\n",
    "    \n",
    "    Returns:\n",
    "        preprocessed_image (numpy.ndarray): The preprocessed image ready for further analysis.\n",
    "    \"\"\"\n",
    "    # Convert the PIL Image to an OpenCV image (PIL uses RGB, OpenCV uses BGR)\n",
    "    open_cv_image = np.array(image) \n",
    "    # Convert RGB to BGR \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy() \n",
    "    \n",
    "    # Step 1: Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Step 2: Apply Gaussian blur to smooth out the image\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    \n",
    "    # Step 3: Apply adaptive thresholding to create a binary image\n",
    "    threshold_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                            cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Step 4: Find edges using the Canny edge detector\n",
    "    edged_image = cv2.Canny(threshold_image, 50, 150)\n",
    "    \n",
    "    return edged_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb55b4ec-6826-4576-bbc7-294046be98fe",
   "metadata": {},
   "source": [
    "## detect_sudoku_grid(preprocessed_image): Detect the grid and segment it into individual cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4788728-03bc-4799-98ca-6cab3074a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sudoku_grid(preprocessed_image):\n",
    "    \"\"\"\n",
    "    Detect the Sudoku grid and divide it into 9x9 cells.\n",
    "    \n",
    "    Parameters:\n",
    "        preprocessed_image (numpy.ndarray): The preprocessed image of the Sudoku puzzle.\n",
    "        \n",
    "    Returns:\n",
    "        cells (list of numpy.ndarray): List of 9x9 cell images of the Sudoku grid.\n",
    "    \"\"\"\n",
    "    # Step 1: Find contours\n",
    "    contours, _ = cv2.findContours(preprocessed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Assume the largest contour is the Sudoku grid\n",
    "    max_area = 0\n",
    "    sudoku_contour = None\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            sudoku_contour = contour\n",
    "    \n",
    "    if sudoku_contour is None:\n",
    "        print(\"Sudoku grid not found\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Apply perspective transform to get a top-down view of the Sudoku grid\n",
    "    # Find the corners of the grid\n",
    "    peri = cv2.arcLength(sudoku_contour, True)\n",
    "    approx = cv2.approxPolyDP(sudoku_contour, 0.02 * peri, True)\n",
    "    \n",
    "    if len(approx) != 4:\n",
    "        print(\"Could not find corners of the grid\")\n",
    "        return None\n",
    "    \n",
    "    # Order the corners\n",
    "    ordered_corners = order_points(np.squeeze(approx))\n",
    "    \n",
    "    # The maximum width and height of the grid\n",
    "    side = max([\n",
    "        np.linalg.norm(ordered_corners[0] - ordered_corners[1]),\n",
    "        np.linalg.norm(ordered_corners[1] - ordered_corners[2]),\n",
    "        np.linalg.norm(ordered_corners[2] - ordered_corners[3]),\n",
    "        np.linalg.norm(ordered_corners[3] - ordered_corners[0])\n",
    "    ])\n",
    "    \n",
    "    # Destination points for the perspective transform\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [side - 1, 0],\n",
    "        [side - 1, side - 1],\n",
    "        [0, side - 1]], dtype=\"float32\")\n",
    "    \n",
    "    # Apply perspective transform\n",
    "    M = cv2.getPerspectiveTransform(ordered_corners, dst)\n",
    "    warped = cv2.warpPerspective(preprocessed_image, M, (int(side), int(side)))\n",
    "    \n",
    "    # Step 3: Divide the warped image into 9x9 cells\n",
    "    cells = []\n",
    "    cell_size = side / 9\n",
    "    for i in range(9):\n",
    "        row = []\n",
    "        for j in range(9):\n",
    "            start_x = int(j * cell_size)\n",
    "            start_y = int(i * cell_size)\n",
    "            cell = warped[start_y:start_y + int(cell_size), start_x:start_x + int(cell_size)]\n",
    "            row.append(cell)\n",
    "        cells.append(row)\n",
    "    \n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7dae311-c980-4c25-93ff-5df20540541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    \"\"\"\n",
    "    Order the points in clockwise order starting from the top-left point.\n",
    "    \"\"\"\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3a81d-5358-4562-a35a-fb04ea6e2367",
   "metadata": {},
   "source": [
    "## preprocess_for_mnist(cell): Preprocess a cell image for MNIST model compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e07d303-65e8-4543-870b-8add0c0f4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_mnist(cell):\n",
    "    # Resize to 28x28, the size used by MNIST\n",
    "    resized = cv2.resize(cell, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY) if len(resized.shape) == 3 else resized\n",
    "    # Scale pixel values to 0-1\n",
    "    scaled = gray / 255.0\n",
    "    # Expand dimensions to match the input shape for the CNN (1x28x28x1)\n",
    "    expanded = np.expand_dims(scaled, axis=-1)\n",
    "    return np.expand_dims(expanded, axis=0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b36226-c70f-45d7-b969-5a9e1f1d510b",
   "metadata": {},
   "source": [
    "## recognize digit(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ddc46b-21eb-4196-a7b0-95c5347bc64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_digit(cell, model):\n",
    "    preprocessed = preprocess_for_mnist(cell)\n",
    "    prediction = model.predict(preprocessed)\n",
    "    return np.argmax(prediction)  # Return the digit with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e955b8e-86fa-42f1-9753-ea94f7fae427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_digits(cells, model):\n",
    "    sudoku_matrix = [[0 for _ in range(9)] for _ in range(9)]\n",
    "    \n",
    "    for i, row in enumerate(cells):\n",
    "        for j, cell in enumerate(row):\n",
    "            # Assuming a simple threshold to identify empty cells\n",
    "            if np.mean(cell) > 127:\n",
    "                sudoku_matrix[i][j] = 0\n",
    "            else:\n",
    "                sudoku_matrix[i][j] = recognize_digit(cell, model) \n",
    "            \n",
    "    return sudoku_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e970335-aa84-4261-882a-7ab94f590f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solve Sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23302ca-ccbf-4545-a8f5-4d144b45b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc07f2-b129-486e-a738-9742d889ab42",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c896a229-b1cf-44cb-ac3e-eecc090c1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Capture the Sudoku puzzle screenshot\n",
    "    screenshot = acquire_image()\n",
    "    \n",
    "    # Preprocess the image to facilitate grid detection\n",
    "    preprocessed_image = preprocess_image(screenshot)\n",
    "    \n",
    "    # Detect the Sudoku grid and extract individual cells\n",
    "    cells = detect_sudoku_grid(preprocessed_image)\n",
    "    \n",
    "    # Path to the pre-trained digit recognition model\n",
    "    model_path = 'my_mnist_model.keras'\n",
    "    \n",
    "    # Load the pre-trained digit recognition model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Recognize digits within each cell to populate the Sudoku matrix\n",
    "    sudoku_matrix = recognize_digits(cells, model)\n",
    "\n",
    "    print (sudoku_matrix)\n",
    "    # (Optional) Solve the Sudoku puzzle\n",
    "    # solved_puzzle = solve_sudoku(sudoku_matrix)\n",
    "    # print_solution(solved_puzzle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a099d8c-7fed-4c0d-a7fa-1d1de9ceb0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "[[7, 7, 7, 7, 7, 7, 7, 7, 7], [7, 7, 2, 7, 7, 7, 7, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 5], [7, 7, 7, 7, 7, 7, 7, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [7, 7, 7, 7, 7, 7, 7, 9, 5]]\n"
     ]
    }
   ],
   "source": [
    "# Run the main program\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c99c549-5bc1-45e0-bec4-e1971dc8d3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
